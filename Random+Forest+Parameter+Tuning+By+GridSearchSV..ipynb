{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest: Predicting which properties get sold at foreclosure sale using Texas Harris County 2017 Foreclosure Sales data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Each month thousands of real estate properties are listed for foreclosure auction by lenders in Harris County in Texas. However, more than 80% get cancelled or delayed because of different reasons. Below I try to predict such cancellation using actual data from 2017.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step: 1) Data loading and cleaning\n",
    "- Step: 2) Formatting data for machine learning \n",
    "- Step: 3) Cross validation to assess the performance of three predictive models\n",
    "- Step: 4) Select the best model and tune its hyper parameters using pipeline and GridSearchCV modules\n",
    "- Step: 5) Use the tuned model to assess its predicitive power on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "path1 = (\"C:/Users/aath/Dropbox/MAEN/Thankful/Data/fls/FLS_Hist2017_clean.csv\")\n",
    "df = pd.read_csv(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec_num                  0\n",
       "keymap                1022\n",
       "sold3rd                  0\n",
       "tax_id                 439\n",
       "org_loan_amt           361\n",
       "mon_org_loan_date      277\n",
       "year_org_loan_date     279\n",
       "sale_date                0\n",
       "est_loan_bal           857\n",
       "mortgagee               28\n",
       "bedr_num              1286\n",
       "prop_val               506\n",
       "Term                  1005\n",
       "Trustee                  1\n",
       "sq_ft                  614\n",
       "time_sold             3591\n",
       "trustee_ref_num       4762\n",
       "open_bid              4359\n",
       "final_bid             3605\n",
       "loan_type               43\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check null status of the columns\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Eliminate few rows with nulls \n",
    "df = df[pd.notnull(df['Trustee'])]\n",
    "df = df[pd.notnull(df['mortgagee'])]\n",
    "df = df[pd.notnull(df['loan_type'])]\n",
    "df = df.drop('rec_num', 1)   # This is an arbitrary index and should be removed\n",
    "\n",
    "# This is the actual sales dates in 2017. This is time-series which we will ignore here\n",
    "df = df.drop('sale_date', 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop all other columns with many nulls\n",
    "df=df.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_df = df.drop('sold3rd', 1)  # Create feature matrix\n",
    "labels_df = df['sold3rd']            # create target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mortgagee\n",
      "854\n",
      "Trustee\n",
      "300\n",
      "loan_type\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Check to see how many unique categories we may need to create\n",
    "categorical = features_df.select_dtypes(include=['object'])\n",
    "for i in categorical:\n",
    "    column = categorical[i]\n",
    "    print(i)\n",
    "    print(column.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mortgagee' 'Trustee' 'loan_type']\n"
     ]
    }
   ],
   "source": [
    "# Set up feature transforming functions\n",
    "\n",
    "def transform_feature( features_df, column_name ):\n",
    "    unique_values = set( features_df[column_name].tolist() )\n",
    "    transformer_dict = {}\n",
    "    for ii, value in enumerate(unique_values):\n",
    "        transformer_dict[value] = ii\n",
    "\n",
    "    def label_map(y):\n",
    "        return transformer_dict[y]\n",
    "    features_df[column_name] = features_df[column_name].apply( label_map )\n",
    "    return features_df\n",
    "\n",
    "\n",
    "# transformation\n",
    "\n",
    "names_of_columns_to_transform = [\"mortgagee\", \"Trustee\",\"loan_type\"]\n",
    "for column in names_of_columns_to_transform:\n",
    "    features_features_df = transform_feature(features_df, column )\n",
    "\n",
    "print(features_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = features_df.as_matrix()\n",
    "y = labels_df.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aath\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Scores [ 0.86223984  0.86223984  0.86223984  0.86223984  0.86295929]\n",
      "Decision Tree Scores [ 0.82457879  0.82061447  0.81863231  0.82160555  0.78152929]\n",
      "Random Forest Scores [ 0.84241824  0.81367691  0.82854311  0.82953419  0.80536246]\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation for three different models\n",
    "\n",
    "import sklearn.linear_model\n",
    "import sklearn.cross_validation\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y, cv=5 )\n",
    "print(\"Logistic Regression Scores {}\".format(score))\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y, cv=5  )\n",
    "print(\"Decision Tree Scores {}\".format(score))\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestClassifier()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y, cv=5  )\n",
    "print(\"Random Forest Scores {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we tested three different classifiers and all of them preform very similar to each otherâ€™s. However, these algorithms have adjustable variables and we just used the default ones. \n",
    "\n",
    "Let's focus on the Random Forest model and see if we can fine tune its parameters to get better results. We can either manually adjust them or use GridSearchCV tool. This tool will exhaustively search over specified parameter value and report the best ones. However, we should do this search using our best features. And for that we can use SelectKBest tool helping to rank features based on lowest p-values.\n",
    "\n",
    "You may realize that there are many moving parts in this workflow and yet another tool that can help to combine these together is pipeline package. Pipeline chains the transformation step of SelectKBest with the estimation step of RandomForestClassifier into a coherent workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import sklearn.pipeline\n",
    "\n",
    "# Set up modules of pipeline\n",
    "select = sklearn.feature_selection.SelectKBest(k='all')\n",
    "clf = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "# Chain modules into a stepwise list \n",
    "\n",
    "steps = [('feature_selection', select),\n",
    "         ('random_forest', clf)]\n",
    "\n",
    "pipeline = sklearn.pipeline.Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83621079120124442"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create k-Fold cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, cross_val_score\n",
    "\n",
    "# Since the ratio of sold to 3rd party = 1 is much less than class 0 we should use stratified k-fold validation\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# Conduct k-fold cross-validation\n",
    "cv_results = cross_val_score(pipeline, # Pipeline\n",
    "                             X, # Feature matrix\n",
    "                             y, # Target vector\n",
    "                             cv=kf, # Cross-validation technique\n",
    "                             scoring=\"accuracy\", # Loss function\n",
    "                             n_jobs=1) # Use all CPU scores\n",
    "# Calculate mean\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_selection': SelectKBest(k='all', score_func=<function f_classif at 0x000000000C1F8E18>), 'random_forest': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.95      0.91       878\n",
      "          1       0.17      0.06      0.09       131\n",
      "\n",
      "avg / total       0.78      0.84      0.80      1009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aath\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.grid_search\n",
    "\n",
    "k_range = [i+1 for i in range(3)]         # Number of features selected\n",
    "n_range = [i+1 for i in range(50)]        # The number of trees in the forest\n",
    "split_range = [i+2 for i in range(3)]     # The minimum number of samples required to split a node\n",
    "\n",
    "parameters = dict(feature_selection__k=k_range,  \n",
    "              random_forest__n_estimators=n_range,\n",
    "              random_forest__min_samples_split= split_range)\n",
    "\n",
    "cv = sklearn.grid_search.GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "print(pipeline.named_steps)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# fit pipeline on X_train and y_train\n",
    "pipeline.fit( X_train, y_train )\n",
    "\n",
    "# call pipeline.predict() on X_test data to make a set of test predictions\n",
    "y_prediction = pipeline.predict( X_test )\n",
    "\n",
    "# test predictions using sklearn.classification_report()\n",
    "report = sklearn.metrics.classification_report( y_test, y_prediction )\n",
    "\n",
    "# and print the report\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83845391476709619"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84539147670961345"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to confirm the selected hyper parameters give the same result\n",
    "sklearn.ensemble.RandomForestClassifier(n_estimators = 10).fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
